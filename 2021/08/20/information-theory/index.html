<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"sremoon.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.6.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>
<meta name="description" content="看不懂论文，补基础">
<meta property="og:type" content="article">
<meta property="og:title" content="信息论">
<meta property="og:url" content="http://sremoon.github.io/2021/08/20/information-theory/index.html">
<meta property="og:site_name" content="SreMoon&#39;s Lake">
<meta property="og:description" content="看不懂论文，补基础">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-08-20T15:04:38.000Z">
<meta property="article:modified_time" content="2021-09-06T10:57:22.000Z">
<meta property="article:author" content="remoon">
<meta property="article:tag" content="information theory">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://sremoon.github.io/2021/08/20/information-theory/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://sremoon.github.io/2021/08/20/information-theory/","path":"2021/08/20/information-theory/","title":"信息论"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>信息论 | SreMoon's Lake</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">SreMoon's Lake</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">conjugate but not similar</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#information-theory"><span class="nav-text">Information theory</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#entropy"><span class="nav-text">Entropy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#relative-entropy"><span class="nav-text">Relative entropy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mutual-information"><span class="nav-text">Mutual information</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#entropy-bound"><span class="nav-text">Entropy Bound</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#entropy-rate"><span class="nav-text">Entropy rate</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#data-compression"><span class="nav-text">Data Compression</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#kraft-inequality"><span class="nav-text">Kraft inequality</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#shannon-codes"><span class="nav-text">Shannon codes</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#huffman-codes"><span class="nav-text">Huffman codes</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#shannon-fano-elias-coding"><span class="nav-text">Shannon-Fano-Elias coding</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#channel"><span class="nav-text">Channel</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#discrete-memoryless-channel"><span class="nav-text">Discrete memoryless channel</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#channel-coding"><span class="nav-text">Channel coding</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#typical-set"><span class="nav-text">Typical set</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#source-channel-coding-theorem"><span class="nav-text">Source-channel coding theorem</span></a></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="remoon"
      src="/images/lalala.jpg">
  <p class="site-author-name" itemprop="name">remoon</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/sremoon" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;sremoon" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



          </div>
        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://sremoon.github.io/2021/08/20/information-theory/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lalala.jpg">
      <meta itemprop="name" content="remoon">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SreMoon's Lake">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          信息论
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-20 23:04:38" itemprop="dateCreated datePublished" datetime="2021-08-20T23:04:38+08:00">2021-08-20</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-09-06 18:57:22" itemprop="dateModified" datetime="2021-09-06T18:57:22+08:00">2021-09-06</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/notes/" itemprop="url" rel="index"><span itemprop="name">notes</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>10 mins.</span>
    </span>
</div>

            <div class="post-description">看不懂论文，补基础</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <span id="more"></span>
<p>临时补一下...</p>
<h2 id="information-theory">Information theory</h2>
<h3 id="entropy">Entropy</h3>
<p>对于离散型随机变量<span class="math inline">\(X\)</span>，出于方便，我们用<span class="math inline">\(|X|\)</span>来表示其样本空间的大小，那么，我们定义随机变量<span class="math inline">\(X\)</span>的熵（entropy）</p>
<p><span class="math display">\[\begin{align}H(X) = \sum_{x \in X} -p(x) \log p(x)  = \sum_{x \in X} p(x) \log \frac{1}{p(x)} \end{align}\]</span></p>
<p>（特别的，如果<span class="math inline">\(p(x) = 0\)</span>，认为<span class="math inline">\(p(x) \log \frac{1}{p(x)} = 0\)</span>）</p>
<p>熵有下列的性质</p>
<ul>
<li><p>如果<span class="math inline">\(X\)</span>均匀随机，那么<span class="math inline">\(H(X) = |X| * \frac{1}{|X|} * \log |X| = \log |X|\)</span></p></li>
<li><p><span class="math inline">\(0 \leq H(X) \leq \log |X|\)</span></p>
<ul>
<li><p>不等式左边成立当且仅当<span class="math inline">\(X\)</span>只在一个地方取得概率<span class="math inline">\(1\)</span>，其余地方取得概率<span class="math inline">\(0\)</span></p></li>
<li><p>不等式右边成立当且仅当<span class="math inline">\(X\)</span>​均匀分布</p></li>
<li><p>不等式的左边是显然的，右边则考虑函数<span class="math inline">\(x \log x\)</span>的凸性</p></li>
</ul></li>
</ul>
<p>对于服从二项分布的<span class="math inline">\(X\)</span>，有特殊的一种熵（Binary entropy function）</p>
<p><span class="math display">\[\begin{align}H(p) = H(X) = p \log \frac{1}{p}  + (1-p) \log \frac{1}{1-p} \end{align}\]</span></p>
<p>熵的定义只依赖于概率分布，只要确定了概率分布，我们就可以定义出熵，因此，在二元情况下，我们可以定义</p>
<p><span class="math display">\[\begin{align}H(X, Y) = \sum_{x \in X, y \in Y} p(x, y) \log \frac{1}{p(x, y)} \end{align}\]</span></p>
<p>为联合熵（joint entropy）</p>
<ul>
<li><span class="math inline">\(H(X, X) = H(X)\)</span>​</li>
<li><span class="math inline">\(H(X, Y) = H(Y, X)\)</span>​</li>
</ul>
<p>定义</p>
<p><span class="math display">\[\begin{align} H(X | Y = y) = \sum_x p(x | Y = y) \log \frac{1}{p(x|Y=y)} \end{align}\]</span></p>
<p><span class="math display">\[\begin{align}H(X|Y) &amp;= \sum_{y \in Y} p(y) H(X | Y = y) \\ &amp;= \sum_{y \in Y} p(y) \sum_{x \in X} p(x | y) \log \frac{1}{p(x | y)} \\ &amp;= \sum_{x \in X, y \in Y} p(x, y) \log \frac{1}{p(x|y)}\end{align}\]</span>​</p>
<p>其中第二项称为条件熵（conditional entropy）</p>
<p>注意到</p>
<p><span class="math display">\[\begin{align} \log p(x|y) = \log \frac{p(x, y)}{p(y)} = \log p(x, y) - \log p(y)\end{align}\]</span>​</p>
<p>（式中的<span class="math inline">\(p(y)\)</span>为对应的边缘分布函数）</p>
<p>我们有</p>
<p><span class="math display">\[\begin{align} H(X|Y) = H(X, Y) - H(Y)\end{align}\]</span></p>
<p>由对称性，得到</p>
<p><span class="math display">\[\begin{align} H(X,Y) = H(Y) + H(X|Y) = H(X) + H(Y | X)\end{align}\]</span></p>
<p>我们可以得到链式法则</p>
<p><span class="math display">\[\begin{align} H(X_1, X_2, ..., X_n) &amp;= H(X_1) + H(X_2, ..., X_n|X_1) \\ &amp;= H(X_1) +H(X_2 | X_1) + H(X_3,...,X_n | X_1, X_2) \\ &amp;= \sum_{i=1}^n H(X_i | X_{1}, ..., X_{i-1})\end{align}\]</span>​</p>
<ul>
<li>当<span class="math inline">\(X, Y\)</span>独立时，<span class="math inline">\(H(X, Y) = H(X) + H(Y)\)</span></li>
<li>贝叶斯公式：<span class="math inline">\(H(X, Y | Z) = H(X|Z) + H(Y | X, Z)\)</span>
<ul>
<li>注意到<span class="math inline">\(p(x, y | z) = \frac{p(x, y, z)}{p(z)} = \frac{p(x, y, z)}{p(x, z)} * \frac{p(x, z)}{p(z)} = p(y|x, z) * p(x|z)\)</span></li>
</ul></li>
<li>当且仅当<span class="math inline">\(Y\)</span>是<span class="math inline">\(X\)</span>的一个函数时，<span class="math inline">\(H(Y|X) = 0\)</span>，也即<span class="math inline">\(H(X, Y) = H(X)\)</span></li>
</ul>
<h3 id="relative-entropy">Relative entropy</h3>
<p>对于概率函数<span class="math inline">\(p(x), q(x)\)</span>，定义</p>
<p><span class="math display">\[\begin{align} D(p || q) = \sum_{x \in X} p(x) \log \frac{p(x)}{q(x)}\end{align}\]</span></p>
<p>为相对熵（relative entropy），也称KL距离，用于衡量两个概率函数之间的“距离”</p>
<p>但是KL距离并不是一种度量（metric）</p>
<ul>
<li><p>当<span class="math inline">\(p(x) = 0\)</span>时，<span class="math inline">\(0 \log \frac{0}{q(x)} = 0\)</span>，反之若<span class="math inline">\(p(x) \neq 0, q(x) = 0\)</span>时，<span class="math inline">\(p(x) \log \frac{p(x)}{0} = \infty\)</span></p></li>
<li><p><span class="math inline">\(D(p || q) \geq 0\)</span>​，当且仅当<span class="math inline">\(p = q\)</span>时取等​</p>
<ul>
<li><p><span class="math inline">\(-D(p || q) = \sum_{x\in X} - p(x) \log \frac{q(x)}{p(x)} \leq \log \sum q(x) \leq \log 1 = 0\)</span></p>
<p>其中第一步为琴生不等式</p>
<p>当且仅当<span class="math inline">\(q(x)/p(x) \equiv C\)</span>，并且<span class="math inline">\(\sum q(x) = 1\)</span>时取等，从而<span class="math inline">\(1 = \sum p(x) = \frac{1}{C} \sum q(x) = \frac {1}{C}\)</span>，于是<span class="math inline">\(C = 1\)</span>，进而<span class="math inline">\(p(x) = q(x)\)</span>，对于<span class="math inline">\(0\)</span>的讨论这里略去</p></li>
</ul></li>
</ul>
<p>定义差分距离（也即向量的1-范数）</p>
<p><span class="math display">\[\begin{align} V(p, q) = \sum_{x \in X} |p(x) - q(x)|\end{align}\]</span></p>
<p>Pinsker 不等式：<span class="math inline">\(D(p || q) \geq \frac{1}{2 \ln 2} V^2(p, q)\)</span>​​（不懂，先记着）</p>
<p>对于<span class="math inline">\(p(x, y), q(x, y)\)</span>，定义条件相对熵为</p>
<p><span class="math display">\[\begin{align} D( p(y|x) || q(y|x)) &amp;= \sum_{x} p(x) D(p(Y|x)||q(Y|x)) \\ &amp;= \sum_x \sum_y p(x)p(y|x) \log \frac{p(y|x)}{q(y|x)} \\ &amp;= \sum_{x, y} p(x, y) \log \frac{ p(y|x)}{q(y|x)}\end{align}\]</span>​</p>
<p>有了条件相对熵之后，就可以类比的写出链式法则</p>
<p><span class="math display">\[\begin{align} D(p(x, y) || q(x, y)) = D(p(x) || q(x)) + D(p(y|x) || q(y|x))\end{align}\]</span></p>
<p>只需注意到<span class="math inline">\(\log \frac{p(x, y)}{q(x, y)} = \log \frac{p(x) p(y|x)}{q(x) q(y|x)} = \log \frac{p(x)}{q(x)} + \log \frac{p(y|x)}{q(y|x)}\)</span></p>
<h3 id="mutual-information">Mutual information</h3>
<p>定义</p>
<p><span class="math display">\[\begin{align} I(X;Y) &amp;= D(p(x, y) || p(x)p(y)) \\ &amp;= \sum_{x \in X, y \in Y} p(x, y) \log \frac{p(x, y)}{p(x)p(y)}\end{align}\]</span></p>
<p>为<span class="math inline">\(X, Y\)</span>的互信息（mutual information）</p>
<ul>
<li><span class="math inline">\(I(X;Y) = I(Y;X)\)</span></li>
<li><span class="math inline">\(I(X;X) = H(X)\)</span>​</li>
<li>既然<span class="math inline">\(I(X;Y)\)</span>是一个KL距离，那么<span class="math inline">\(I(X;Y) \geq 0\)</span>​，等号成立当且仅当<span class="math inline">\(p(x, y) = p(x)p(y)\)</span>，即<span class="math inline">\(X, Y\)</span>独立</li>
</ul>
<p>由于<span class="math inline">\(\log \frac{p(x, y)}{p(x)p(y)} = \log p(x, y) - \log p(x) - \log p(y)\)</span></p>
<p>因此</p>
<p><span class="math display">\[\begin{align} I(X;Y) &amp;= H(X) + H(Y) - H(X, Y) \\ &amp;= H(X) - H(X | Y)\\ &amp;= H(Y) - H(Y|X)\end{align}\]</span>​</p>
<ul>
<li>由<span class="math inline">\(I(X;Y) = H(X) - H(X|Y) \geq 0\)</span>​，那么<span class="math inline">\(H(X|Y) \leq H(X)\)</span>​​，当<span class="math inline">\(X, Y\)</span>​独立时取等</li>
<li><span class="math inline">\(I(X;Y) \leq H(X)\)</span></li>
</ul>
<p>定义</p>
<p><span class="math display">\[\begin{align} I(X;Y | Z) &amp;= \sum_{x, y, z} p(x ,y, z) \log \frac{p(x, y | z)}{p(x|z) p(y|z) } \\ &amp;= H(X|Z) - H(X|Y,Z)\end{align}\]</span>​</p>
<p>当且仅当在给定<span class="math inline">\(Z\)</span>的情况下，<span class="math inline">\(X, Y\)</span>独立时取等</p>
<p>计算条件互信息时，有链式法则</p>
<p><span class="math display">\[\begin{align} I(X_1, X_2, ..., X_n ; Y) = \sum_{i=1}^n I(X_i ; Y|X_1, X_2, ..., X_{i-1})\end{align}\]</span></p>
<h3 id="entropy-bound">Entropy Bound</h3>
<p><span class="math display">\[H(X_1, X_2, ..., X_n) \leq \sum_{i=1}^n H(X_i)\]</span></p>
<p>取等当且仅当<span class="math inline">\(X_1, ..., X_n\)</span>独立（用链式法则证明）</p>
<p>接下来要引入马尔科夫链，称<span class="math inline">\(X, Y, Z\)</span>形成马尔科夫链，当且仅当</p>
<p><span class="math display">\[\begin{align} p(x, y, z) = p(x)p(y|x)p(z|y)\end{align}\]</span></p>
<p>（也就是<span class="math inline">\(p(z|y) = p(z|x, y)\)</span>），写作<span class="math inline">\(X \to Y \to Z\)</span></p>
<ul>
<li><p>如果<span class="math inline">\(X\to Y \to Z\)</span>，那么<span class="math inline">\(I(X;Z|Y) = 0\)</span></p></li>
<li><p>如果<span class="math inline">\(X \to Y \to Z\)</span>，那么<span class="math inline">\(I(X;Y) \geq I(X;Z)\)</span></p>
<ul>
<li><span class="math inline">\(I(X;Y) - I(X;Z) = I(X;Y,Z) - I(X;Z|Y) - (I(X;Y,Z) - I(X;Y|Z)) = I(X;Y|Z) \geq 0\)</span></li>
<li>由上述等式，还能观察到<span class="math inline">\(I(X;Y) \geq I(X;Y|Z)\)</span></li>
<li>但是，一般情况下，<span class="math inline">\(I(X;Y) \geq I(X;Y|Z)\)</span>不一定成立</li>
</ul></li>
<li><p>如果<span class="math inline">\(X \to Y \to Z\)</span>，那么<span class="math inline">\(H(X|Z) \geq H(X|Y)\)</span></p></li>
<li><p>$ H(X|Z) - H(X|Y,Z) = I(X;Y|Z)I(X;Z|Y) = H(X|Y) - H(X|Y,Z)$</p></li>
</ul>
<h3 id="entropy-rate">Entropy rate</h3>
<p>稳态过程，一个随机过程称为稳态，如果其任意子集的联合分布具有时间不变性，</p>
<p><span class="math display">\[\begin{align} \forall n, l, x_1, x_2,..., x_n \in X, P(X_1 = x_1, X_2 = x_2, ..., X_n = x_n) = P(X_{1+l} = x_1, ..., X_{n+l} = x_n)\end{align}\]</span></p>
<p>稳态过程具有时间可逆性，即</p>
<p><span class="math display">\[\begin{align} H(X_0 | X_{-1},X_{-2},..X_{-n}) = H(X_0 | X_1, X_2, ..., X_n)\end{align}\]</span></p>
<p>而对于马尔科夫链，其为稳态充要条件为<span class="math inline">\(p(X_{n+1}) = p(X_n)\)</span></p>
<p>或者说<span class="math inline">\(P(x_1,x_2,...,x_n)^T = (x_1, ..., x_n)^T\)</span>，其中<span class="math inline">\(P\)</span>为转移矩阵</p>
<hr />
<p>对于随机过程，定义熵率</p>
<p><span class="math display">\[\begin{align} H(X) = \lim_{n \to \infty} \frac{1}{n} H(X_1, X_2, ..., X_n)\end{align}\]</span></p>
<p>熵率不一定存在，但对于稳态而言，熵率是存在的</p>
<p>我们先考虑<span class="math inline">\(A_n = H(X_n | X_{n-1}, ..., X_1)\)</span></p>
<p>注意到<span class="math inline">\(0 \leq A_{n+1} = H(X_{n+1} | X_{n},...,X_1) \leq H(X_{n+1} | X_n,...,X_2) = H(X_n | X_{n-1},...,X_1) = A_n\)</span>，<span class="math inline">\(A_n\)</span>单调递减有下限，因此<span class="math inline">\(A_n\)</span>有极限</p>
<p>那么</p>
<p><span class="math display">\[\begin{align} H&#39;(X) = \lim_{n \to \infty} H(X_n | X_{n-1},...,X_1)\end{align}\]</span></p>
<p>存在，根据数学分析中的结论，我们有</p>
<p><span class="math display">\[\begin{align} H(X) = H&#39;(X)\end{align}\]</span></p>
<p>存在</p>
<p>特别的，对于稳态马尔科夫链，将有<span class="math inline">\(H(X) = H&#39;(X) = H(X_2 | X_1)\)</span></p>
<p>如果设出马尔科夫链的极限分布<span class="math inline">\(\pi\)</span>和转移矩阵<span class="math inline">\(P\)</span>，那么我们将得到</p>
<p><span class="math display">\[\begin{align} H(X) = \sum_{ij} \pi_i P_{ij} \log \frac{1}{P_{ij}}\end{align}\]</span></p>
<hr />
<p>设<span class="math inline">\(Y = f(X)\)</span>，如果<span class="math inline">\(\{X\}\)</span>构成稳态的马尔科夫链，那么<span class="math inline">\(\{Y\}\)</span>也构成稳态的马尔科夫链</p>
<ul>
<li><span class="math inline">\(p(X_{n+1}) = p(X_n) \Rightarrow p(Y_{n+1}) = p(Y_n)\)</span></li>
</ul>
<p>那么，<span class="math inline">\(H(Y) = \lim_{n \to \infty} H(Y_n | Y_{n-1}, ..., Y_1)\)</span></p>
<p>通过一些（奇怪的）技巧，我们可以对<span class="math inline">\(H(Y)\)</span>进行更好的估值，这依赖于以下定理</p>
<p><span class="math display">\[\begin{align} H(Y_n | Y_{n-1},...,Y_1, X_1) \leq H(y) \leq H(Y_n | Y_{n-1},...,Y_1)\end{align}\]</span></p>
<p><span class="math display">\[\begin{align} \lim_{n \to \infty} H(Y_n | Y_{n-1},...,Y_1,X_1) = \lim_{n \to \infty} H(Y_n|Y_{n-2},...,Y_1) = H(y)\end{align}\]</span>​</p>
<ul>
<li>注意到<span class="math inline">\(Y\)</span>是<span class="math inline">\(X\)</span>的函数，尝试在熵的已知中添加<span class="math inline">\(Y\)</span></li>
</ul>
<h3 id="data-compression">Data Compression</h3>
<p>大概到了新的阶段</p>
<p>对于一个随机变量<span class="math inline">\(X\)</span>的信源编码（source code），是一个从随机变量<span class="math inline">\(X\)</span>的样本空间到一个有限长度的字符串的映射（不妨设字母表为<span class="math inline">\(D\)</span>，记所有的有限长度的字符串的集合为<span class="math inline">\(D^*\)</span>），让<span class="math inline">\(C(x)\)</span>表示对应于<span class="math inline">\(x\)</span>的编码，而<span class="math inline">\(l(x)\)</span>表示<span class="math inline">\(C(x)\)</span>的长度</p>
<p>记<span class="math inline">\(L(C) = E_{p(x)}[l(x)] = \sum_{x} p(x) l(x)\)</span>，一般的，我们希望一个编码方式能够最小化<span class="math inline">\(L(C)\)</span></p>
<p>对于一种编码，称其扩展<span class="math inline">\(C^*\)</span>为以<span class="math inline">\(X\)</span>的样本空间为字符集构成的有限字符串映射到有限长度的字符串的映射，满足<span class="math inline">\(C(x_1 + x_2 + ... + x_n) = C(x_1) + C(x_2) + ... + C(x_n)\)</span>，这里的"+"表示字符串的拼接</p>
<ul>
<li>当一种编码的<strong>扩展</strong>是一个单射时，称这种编码是唯一可解码的</li>
<li>一种编码称为前缀码，或者即时码，如果任意两个码都没有互为前缀，类似的定义后缀码</li>
</ul>
<h5 id="kraft-inequality">Kraft inequality</h5>
<p>Kraft 不等式：对于一种前缀码，设其字母表大小为<span class="math inline">\(D\)</span>​​，那么编码长度<span class="math inline">\(l_1, ..., l_m (m = |X|)\)</span>​​将满足</p>
<p><span class="math display">\[\begin{align} \sum_{i=1}^m D^{-l_i} \leq 1\end{align}\]</span></p>
<p>并且，给定一组满足该不等式的编码长度，那么一定存在一种前缀码以这些长度编码</p>
<ul>
<li>考虑用Trie树表示前缀码，反过来则用归纳法证明</li>
<li>这个结论在编码长度有可数无穷的情况下也是对的，可以考虑用<span class="math inline">\([0,1)\)</span>中的<span class="math inline">\(D\)</span>进制小数来证明</li>
</ul>
<p>利用拉格朗日乘数法，得到最优情况下，我们应该控制编码长度为<span class="math inline">\(l_i = -\log_D p_i(p_i = D^{-l_i})\)</span>，此时<span class="math inline">\(L(C) = H_D(X)\)</span></p>
<p>但是一般的，这个长度不是整数，因此一般的有<span class="math inline">\(L(C) \geq H_D(X)\)</span>​，但是我们有<span class="math inline">\(H_D(X) \leq L(C) &lt; H_D(X) + 1\)</span>​</p>
<h5 id="shannon-codes">Shannon codes</h5>
<p>我们直接取<span class="math inline">\(l_i = \lceil -\log_D p_i \rceil\)</span>，就有<span class="math inline">\(-\log_D p_i \leq l_i &lt; -\log_D p_i + 1\)</span>，于是<span class="math inline">\(H_D(X) \leq L(C) &lt; H_D(X) + 1\)</span>，这种编码称为Shannon codes</p>
<p>进一步，如果我们对<span class="math inline">\(X_1, X_2,...,X_n\)</span>​（样本空间相同）一起编码，运用刚刚的结论，得到</p>
<p><span class="math display">\[H(X_1, ..., X_n) \leq E [l(X_1, ..., X_n)] &lt; H(X_1,...,X_n) + 1\]</span></p>
<blockquote>
<p>将<span class="math inline">\(L(C)\)</span>记为编码一个随机变量所用的期望长度，那么<span class="math inline">\(L(C) = \frac{1}{n} E [l(X_1, ..., X_n)]\)</span>，代入上式，得到 <span class="math display">\[\frac{H(X_1, ..., X_n)}{n} \leq L(C)&lt; \frac{H(X_1,...,X_n) + 1}{n}\]</span></p>
<p>如果<span class="math inline">\(X_1,...,X_n,...\)</span>构成一个稳态的话，根据前文的结论，我们有<span class="math inline">\(L(C) \to H(X)\)</span>（这里为熵率）</p>
</blockquote>
<p>这种编码方式称为区块编码，而上述结论称为香农第一定理</p>
<hr />
<p>如果我们运用<span class="math inline">\(\{q(x)\}\)</span>来给一个概率为<span class="math inline">\(\{p(x)\}\)</span>的随机变量编码，那么我们将有</p>
<p><span class="math display">\[\begin{align} H(p) + D(p||q) \leq E_p \; \lceil\log \frac{1}{q(x)} \rceil &lt; H(p) + D(p || q) + 1\end{align}\]</span>​</p>
<p>当然，这里的<span class="math inline">\(\lceil\log \frac{1}{q(x)} \rceil\)</span>表示编码长度</p>
<p>这个式子只需要对取整号进行简单放缩后，运用定义就可以得到</p>
<hr />
<p>Kraft不等式的约束范围非常非常广，事实上，我们只考虑前缀码就足够了</p>
<p>对于一种唯一可解码，设其字母表大小为<span class="math inline">\(D\)</span>​，那么编码长度<span class="math inline">\(l_1, ..., l_m (m = |X|)\)</span>​将满足</p>
<p><span class="math display">\[\begin{align} \sum_{i=1}^m D^{-l_i} \leq 1\end{align}\]</span></p>
<p>并且，给定一组满足该不等式的编码长度，那么一定存在一种唯一可解码以这些长度编码</p>
<h5 id="huffman-codes">Huffman codes</h5>
<p>哈夫曼编码可以使得<span class="math inline">\(L(C)\)</span>最小，并且哈夫曼编码是一种前缀码</p>
<p>这玩意初中生都会了....就不写了</p>
<p>有个扩展叫canonical codes，就先不学了..。</p>
<h5 id="shannon-fano-elias-coding">Shannon-Fano-Elias coding</h5>
<p>考虑<span class="math inline">\(X\)</span>的分布函数<span class="math inline">\(F(x)\)</span>，定义其MCDF为<span class="math inline">\(F^*(x) = F(x) - \frac{1}{2} p(x)\)</span></p>
<p>不难发现，<span class="math inline">\(F^*(x)\)</span>和<span class="math inline">\(p(x) &gt; 0\)</span>的<span class="math inline">\(x\)</span>​之间存在着对应关系，从而可以用于编码</p>
<p>考虑截取<span class="math inline">\(F^*(x)\)</span>的前<span class="math inline">\(l(x) = \lceil \log \frac{1}{p(x)}\rceil + 1\)</span>位（二进制），那么有<span class="math inline">\(F^*(x) - C(x) \leq \frac{1}{2^{l(x)}} \leq \frac{p(x)}{2} = F^*(x) - F^*(x-1)\)</span></p>
<p>因此这种编码方式也构成一种前缀码，由于多用了1个bit来避免重复，因此此时<span class="math inline">\(L &lt; H(x) + 2\)</span>​</p>
<h3 id="channel">Channel</h3>
<p>一个信道的模型，大概就是对信息进行编码，通过信道（可能有噪声，以一个概率来描述），之后解码</p>
<p>我们假设发送了<span class="math inline">\(w = x_1x_2...x_k\)</span>，经过信道后得到<span class="math inline">\(y_1y_2...y_k\)</span></p>
<p>这些数字的生成是有先后顺序的，<span class="math inline">\(w \to x_1 \to y_1 \to x_2 \to y_2 ... \to x_k \to y_k\)</span></p>
<p>为了表示方便，记<span class="math inline">\(x^i = x_1,x_2...,x_i, y^i = y_1, y_2, ..., y_i\)</span></p>
<p>对于一个好的信道，我们希望它能发送更多的信息，也即熵尽可能大</p>
<h5 id="discrete-memoryless-channel">Discrete memoryless channel</h5>
<p>离散无记忆信道（DMC），满足</p>
<p><span class="math display">\[\begin{align} p(y_k | x^k, y^{k-1}) = p(y_k | x_k) \end{align}\]</span></p>
<p>其中<span class="math inline">\(x_k\)</span>是第<span class="math inline">\(k\)</span>个发送的信息，而<span class="math inline">\(x^k\)</span>为前<span class="math inline">\(k\)</span>次发送的信息，<span class="math inline">\(y^{k-1}\)</span>为前<span class="math inline">\(k-1\)</span>​个发送后的信息</p>
<p>而一个无反馈（feedback）的信道，满足</p>
<p><span class="math display">\[\begin{align} p(x_k | x^{k-1}, y^{k-1}) = p(x_k | x^{k-1})\end{align}\]</span></p>
<p>也就是前<span class="math inline">\(k-1\)</span>次经过信道后的信息对于第<span class="math inline">\(k\)</span>次发送的信息没有影响</p>
<p>结合这两个概率，一般默认DMC是没有反馈的</p>
<p>对于DMC而言，有</p>
<p><span class="math display">\[\begin{align} p(y^n |x^n) =  \prod_{i=1}^n p(y_i | x_i)\end{align}\]</span>​</p>
<p>用熵来表示，就是</p>
<p><span class="math display">\[\begin{align} H(Y^n | X^n) = \sum_{i=1}^n H(Y_i | X_i) \end{align}\]</span>​</p>
<p>运用上式，有</p>
<p><span class="math display">\[H(Y^n) - H(Y^n|X^n)= H(Y^n) - \sum_{i=1}^n H(Y_i | X_i) \leq \sum_{i=1}^n (H(Y_i) - H(Y_i | X_i))\]</span></p>
<p><span class="math display">\[\begin{align} I(X^n ; Y^n) \leq \sum_{i=1}^n I(X_i ; Y_i) \end{align}\]</span></p>
<p>在DMC中，<span class="math inline">\(w \to X^n \to Y^n \to w&#39;\)</span>构成一个马尔科夫链，其中<span class="math inline">\(w&#39;\)</span>​为解码后的信息</p>
<h5 id="channel-coding">Channel coding</h5>
<p>编码器（encoder），是一个将信息映射到<span class="math inline">\(X^n\)</span>的映射，并且要求是单射，类似的有解码器</p>
<p>码本（codebook），记录了编码器的映射规则，码本为发送者和接收者共有</p>
<p>码字（codewords），用<span class="math inline">\(x^n(i)\)</span>表示编码<span class="math inline">\(i\)</span>的字符串</p>
<p>对于一个信道<span class="math inline">\((X, p(y|x), Y)\)</span>​​​而言，其一个编码<span class="math inline">\((M, n)\)</span>包括发送信息的集合（<span class="math inline">\(M\)</span>​），编码器（引申出码本和码字），解码器</p>
<p>为了衡量信道发送的信息是否有误，定义</p>
<p><span class="math display">\[\begin{align}\lambda_i = p( g(Y^n) \neq i | X^n = x^n(i)) = \sum_{y^n} p(y^n | x^n(i))* [g(y^n) \neq i] \end{align}\]</span></p>
<p>定义最大错误概率为</p>
<p><span class="math display">\[\begin{align} \lambda^{(n)} = \max_{i \in [M]} \lambda_i\end{align}\]</span></p>
<p>定义平均错误概率为</p>
<p><span class="math display">\[\begin{align} P_e^{(n)} = \frac{1}{M} \sum_{i=1}^M \lambda_i\end{align}\]</span></p>
<p>对于一个信道编码<span class="math inline">\((M, n)\)</span>​，定义码率为</p>
<p><span class="math display">\[\begin{align} R = \frac{\log M}{n} \end{align}\]</span>​</p>
<p>如果存在一系列的编码<span class="math inline">\((2^{nR}, n)\)</span>，使得当<span class="math inline">\(n \to \infty\)</span>时，<span class="math inline">\(\lambda^{(n)} \to 0\)</span>，就称码率<span class="math inline">\(R\)</span>​是可取的</p>
<p>定义信道容量<span class="math inline">\(C\)</span>为所有可取码率的上确界</p>
<ul>
<li><p>信道编码定理</p>
<p><strong>对于DMC而言，一切小于信道容量<span class="math inline">\(C\)</span>​的码率是可取的</strong></p></li>
<li><p>特别的，对于默认的DMC，<span class="math inline">\(C = \max_{p(x)} I(X;Y)\)</span></p>
<p>而对于有反馈的DMC而言，信道容量并不能得到提高</p></li>
</ul>
<h5 id="typical-set">Typical set</h5>
<p>接下来是一点关于典型集的内容...</p>
<blockquote>
<p>如果<span class="math inline">\(X_1,...,X_n,...\)</span>是i.i.d.的，那么</p>
<p><span class="math display">\[\begin{align} -\frac{1}{n} \log p(X_1,...,X_n) \to H(X) (n \to \infty)\end{align}\]</span>​</p>
</blockquote>
<p>这个性质称为AEP（渐进均分性），根据大数定理，我们知道满足上述条件的<span class="math inline">\(X\)</span>序列的概率和几乎是<span class="math inline">\(1\)</span>​</p>
<p>我们把满足上述条件的序列弄成一个集合<span class="math inline">\(A_{\epsilon}^{(n)}\)</span>​，称为典型集（typical set），形式化的讲就是，如果<span class="math inline">\((x_1,...,x_n) \in X^n\)</span>在集合<span class="math inline">\(A_{\epsilon}^{(n)}\)</span>中，那么</p>
<p><span class="math display">\[\begin{align}2^{-n(H(X) + \epsilon)} \leq p(x_1,...,x_n)  \leq 2^{-n(H(X) - \epsilon)}\end{align}\]</span></p>
<ul>
<li>上述式子等价于：<span class="math inline">\(|\frac{1}{n} \log p(x_1,...,x_n) + H(X)| \leq \epsilon\)</span></li>
<li>根据之前的讨论，当<span class="math inline">\(n\)</span>足够大时，典型集中的序列的概率之和趋近于<span class="math inline">\(1\)</span></li>
<li><span class="math inline">\((1 - \epsilon) 2^{n(H(X) - \epsilon)} \leq |A_{\epsilon}^{(n)}| \leq 2^{n(H(X) - \epsilon)}\)</span>，也就是其大小趋近于<span class="math inline">\(2^{nH(X)}\)</span>​
<ul>
<li>注意到<span class="math inline">\(A_{\epsilon}^{(n)}\)</span>的概率和有上界<span class="math inline">\(1\)</span>，有下界<span class="math inline">\(1- \epsilon\)</span>​</li>
</ul></li>
</ul>
<p>对于两个随机过程，我们可以定义联合典型集</p>
<p>如果<span class="math inline">\((x^n , y^n) \in X^n \times Y^n\)</span>在集合<span class="math inline">\(A_{\epsilon}^{(n)}\)</span>中，那么</p>
<p><span class="math inline">\(2^{-n(H(X) + \epsilon)} \leq p(x^n) \leq 2^{-n(H(X) - \epsilon)}\)</span>​</p>
<p><span class="math inline">\(2^{-n(H(X) + \epsilon)} \leq p(y^n) \leq 2^{-n(H(X) - \epsilon)}\)</span>​</p>
<p><span class="math inline">\(2^{-n(H(X,Y) + \epsilon)} \leq p(x^n, y^n) \leq 2^{-n(H(X, Y) - \epsilon)}\)</span>​</p>
<ul>
<li><p><span class="math inline">\(|A_{\epsilon}^{(n)}| \to 2^{nH(X,Y)}\)</span></p></li>
<li><p>如果<span class="math inline">\((X&#39;, Y&#39;) \sim p(x^n)p(y^n)\)</span>，那么<span class="math inline">\(p((X&#39;, Y&#39;) \in A_{\epsilon}^{(n)}) \to 2^{-nI(X;Y)}\)</span>​</p>
<ul>
<li><p><span class="math inline">\(p((X&#39;, Y&#39;) \in A_{\epsilon}^{(n)}) = \sum_{(x^n, y^n)} p(x^n) p(y^n) \to 2^{nH(X, Y)} * 2^{-nH(X)} * 2^{-nH(Y)} = 2^{-nI(X;Y)}\)</span></p>
<p>式中为集合的大小乘上相应的概率，具体的写法就分两个方向放缩</p></li>
</ul></li>
</ul>
<h5 id="source-channel-coding-theorem">Source-channel coding theorem</h5>
<ul>
<li><p>信源信道联合编码定理</p>
<p>如果<span class="math inline">\(X_1, ..., X_n\)</span>是一个满足渐进均分性，并且<span class="math inline">\(H(X) &lt; C\)</span>，那么存在一种信源信道的联合编码方案，使得<span class="math inline">\(p(X^n \neq (X^n)&#39;) \to 0\)</span></p>
<p>反之，对于任何稳态随机过程，如果<span class="math inline">\(H(X) &gt; C\)</span>，那么不存在使得<span class="math inline">\(p(X^n \neq (X^n)&#39;) \to 0\)</span>的一种联合编码方案</p></li>
</ul>
<p>感觉该知道的都差不多了....先记到这里...</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/information-theory/" rel="tag"># information theory</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/08/05/matrix-analysis-6/" rel="prev" title="矩阵分析 6">
                  <i class="fa fa-chevron-left"></i> 矩阵分析 6
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/09/07/problem-2/" rel="next" title="problem-2">
                  problem-2 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">remoon</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Symbols count total: </span>
    <span title="Symbols count total">90k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">1:22</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
